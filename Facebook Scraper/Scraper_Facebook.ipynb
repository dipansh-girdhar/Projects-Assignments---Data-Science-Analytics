{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scraper Facebook",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dipansh-girdhar/Projects-Assignments---Data-Science-Analytics/blob/master/Facebook%20Scraper/Scraper_Facebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjl1WSZ_RVJr",
        "colab_type": "code",
        "outputId": "6954e606-dbbd-422e-ef0e-77d177c49f85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!pip install selenium"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.6/dist-packages (3.141.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBOWZ3M_RINN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import calendar\n",
        "import os\n",
        "import platform\n",
        "import sys\n",
        "import urllib.request\n",
        "import time\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.support.ui import WebDriverWait"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "457e-_iXROoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "driver = None\n",
        "download_uploaded_photos = True\n",
        "download_friends_photos = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBHHvAjkRjwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "friends_small_size = True\n",
        "photos_small_size = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKwTM_okRo3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "total_scrolls = 500\n",
        "current_scrolls = 0\n",
        "scroll_time = 5\n",
        "\n",
        "old_height = 0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jbwt0JMCRtbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_facebook_images_url(img_links):\n",
        "    urls = []\n",
        "\n",
        "    for link in img_links:\n",
        "        if link != \"None\":\n",
        "            valid_url_found = False\n",
        "            driver.get(link)\n",
        "\n",
        "            try:\n",
        "                while not valid_url_found:\n",
        "                    WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CLASS_NAME, \"spotlight\")))\n",
        "                    element = driver.find_element_by_class_name(\"spotlight\")\n",
        "                    img_url = element.get_attribute('src')\n",
        "\n",
        "                    if img_url.find('.gif') == -1:\n",
        "                        valid_url_found = True\n",
        "                        urls.append(img_url)\n",
        "            except:\n",
        "                urls.append(\"None\")\n",
        "        else:\n",
        "            urls.append(\"None\")\n",
        "\n",
        "    return urls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tLf5Jr-Ry9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_downloader(img_links, folder_name):\n",
        "    img_names = []\n",
        "\n",
        "    try:\n",
        "        parent = os.getcwd()\n",
        "        try:\n",
        "            folder = os.path.join(os.getcwd(), folder_name)\n",
        "            create_folder(folder)\n",
        "            os.chdir(folder)\n",
        "        except:\n",
        "            print(\"Error in changing directory.\")\n",
        "\n",
        "        for link in img_links:\n",
        "            img_name = \"None\"\n",
        "\n",
        "            if link != \"None\":\n",
        "                img_name = (link.split('.jpg')[0]).split('/')[-1] + '.jpg'\n",
        "\n",
        "                # this is the image id when there's no profile pic\n",
        "                if img_name == \"10354686_10150004552801856_220367501106153455_n.jpg\":\n",
        "                    img_name = \"None\"\n",
        "                else:\n",
        "                    try:\n",
        "                        urllib.request.urlretrieve(link, img_name)\n",
        "                    except:\n",
        "                        img_name = \"None\"\n",
        "\n",
        "            img_names.append(img_name)\n",
        "\n",
        "        os.chdir(parent)\n",
        "    except:\n",
        "        print(\"Exception (image_downloader):\", sys.exc_info()[0])\n",
        "\n",
        "    return img_names\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVCBxV81SB0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_height():\n",
        "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "    return new_height != old_height"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al7RDuycSJ2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scroll():\n",
        "    global old_height\n",
        "    current_scrolls = 0\n",
        "\n",
        "    while (True):\n",
        "        try:\n",
        "            if current_scrolls == total_scrolls:\n",
        "                return\n",
        "\n",
        "            old_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "            WebDriverWait(driver, scroll_time, 0.05).until(lambda driver: check_height())\n",
        "            current_scrolls += 1\n",
        "        except TimeoutException:\n",
        "            break\n",
        "\n",
        "    return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxAJH1LMSNiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_status(x):\n",
        "    status = \"\"\n",
        "    try:\n",
        "        status = x.find_element_by_xpath(\".//div[@class='_5wj-']\").text\n",
        "    except:\n",
        "        try:\n",
        "            status = x.find_element_by_xpath(\".//div[@class='userContent']\").text\n",
        "        except:\n",
        "            pass\n",
        "    return status"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1spOT0YuSRYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_div_links(x, tag):\n",
        "    try:\n",
        "        temp = x.find_element_by_xpath(\".//div[@class='_3x-2']\")\n",
        "        return temp.find_element_by_tag_name(tag)\n",
        "    except:\n",
        "        return \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_uqTRFESVpD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_title_links(title):\n",
        "    l = title.find_elements_by_tag_name('a')\n",
        "    return l[-1].text, l[-1].get_attribute('href')\n",
        "\n",
        "\n",
        "def get_title(x):\n",
        "    title = \"\"\n",
        "    try:\n",
        "        title = x.find_element_by_xpath(\".//span[@class='fwb fcg']\")\n",
        "    except:\n",
        "        try:\n",
        "            title = x.find_element_by_xpath(\".//span[@class='fcg']\")\n",
        "        except:\n",
        "            try:\n",
        "                title = x.find_element_by_xpath(\".//span[@class='fwn fcg']\")\n",
        "            except:\n",
        "                pass\n",
        "    finally:\n",
        "        return title"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3uwkmnASZFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_time(x):\n",
        "    time = \"\"\n",
        "    try:\n",
        "        time = x.find_element_by_tag_name('abbr').get_attribute('title')\n",
        "        time = str(\"%02d\" % int(time.split(\", \")[1].split()[1]), ) + \"-\" + str(\n",
        "            (\"%02d\" % (int((list(calendar.month_abbr).index(time.split(\", \")[1].split()[0][:3]))),))) + \"-\" + \\\n",
        "               time.split()[3] + \" \" + str(\"%02d\" % int(time.split()[5].split(\":\")[0])) + \":\" + str(\n",
        "            time.split()[5].split(\":\")[1])\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    finally:\n",
        "        return time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tDwFrSvSgbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_and_write_posts(elements, filename):\n",
        "    try:\n",
        "        f = open(filename, \"w\", newline='\\r\\n')\n",
        "        f.writelines(' TIME || TYPE  || TITLE || STATUS  ||   LINKS(Shared Posts/Shared Links etc) ' + '\\n' + '\\n')\n",
        "\n",
        "        for x in elements:\n",
        "            try:\n",
        "                video_link = \" \"\n",
        "                title = \" \"\n",
        "                status = \" \"\n",
        "                link = \"\"\n",
        "                img = \" \"\n",
        "                time = \" \"\n",
        "\n",
        "                # time\n",
        "                time = get_time(x)\n",
        "\n",
        "                # title\n",
        "                title = get_title(x)\n",
        "                if title.text.find(\"shared a memory\") != -1:\n",
        "                    x = x.find_element_by_xpath(\".//div[@class='_1dwg _1w_m']\")\n",
        "                    title = get_title(x)\n",
        "\n",
        "                status = get_status(x)\n",
        "                if title.text == driver.find_element_by_id(\"fb-timeline-cover-name\").text:\n",
        "                    if status == '':\n",
        "                        temp = get_div_links(x, \"img\")\n",
        "                        if temp == '':  # no image tag which means . it is not a life event\n",
        "                            link = get_div_links(x, \"a\").get_attribute('href')\n",
        "                            type = \"status update without text\"\n",
        "                        else:\n",
        "                            type = 'life event'\n",
        "                            link = get_div_links(x, \"a\").get_attribute('href')\n",
        "                            status = get_div_links(x, \"a\").text\n",
        "                    else:\n",
        "                        type = \"status update\"\n",
        "                        if get_div_links(x, \"a\") != '':\n",
        "                            link = get_div_links(x, \"a\").get_attribute('href')\n",
        "\n",
        "                elif title.text.find(\" shared \") != -1:\n",
        "\n",
        "                    x1, link = get_title_links(title)\n",
        "                    type = \"shared \" + x1\n",
        "\n",
        "                elif title.text.find(\" at \") != -1 or title.text.find(\" in \") != -1:\n",
        "                    if title.text.find(\" at \") != -1:\n",
        "                        x1, link = get_title_links(title)\n",
        "                        type = \"check in\"\n",
        "                    elif title.text.find(\" in \") != 1:\n",
        "                        status = get_div_links(x, \"a\").text\n",
        "\n",
        "                elif title.text.find(\" added \") != -1 and title.text.find(\"photo\") != -1:\n",
        "                    type = \"added photo\"\n",
        "                    link = get_div_links(x, \"a\").get_attribute('href')\n",
        "\n",
        "                elif title.text.find(\" added \") != -1 and title.text.find(\"video\") != -1:\n",
        "                    type = \"added video\"\n",
        "                    link = get_div_links(x, \"a\").get_attribute('href')\n",
        "\n",
        "                else:\n",
        "                    type = \"others\"\n",
        "\n",
        "                if not isinstance(title, str):\n",
        "                    title = title.text\n",
        "\n",
        "                status = status.replace(\"\\n\", \" \")\n",
        "                title = title.replace(\"\\n\", \" \")\n",
        "\n",
        "                line = str(time) + \" || \" + str(type) + ' || ' + str(title) + ' || ' + str(status) + ' || ' + str(\n",
        "                    link) + \"\\n\"\n",
        "\n",
        "                try:\n",
        "                    f.writelines(line)\n",
        "                except:\n",
        "                    print('Posts: Could not map encoded characters')\n",
        "            except:\n",
        "                pass\n",
        "        f.close()\n",
        "    except:\n",
        "        print(\"Exception (extract_and_write_posts)\", \"Status =\", sys.exc_info()[0])\n",
        "\n",
        "    return\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiOekvFqSoW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_to_file(name, elements, status, current_section):\n",
        "    \"\"\"helper function used to save links to files\"\"\"\n",
        "\n",
        "    # status 0 = dealing with friends list\n",
        "    # status 1 = dealing with photos\n",
        "    # status 2 = dealing with videos\n",
        "    # status 3 = dealing with about section\n",
        "    # status 4 = dealing with posts\n",
        "\n",
        "    try:\n",
        "        f = None  # file pointer\n",
        "\n",
        "        if status != 4:\n",
        "            f = open(name, 'w', encoding='utf-8', newline='\\r\\n')\n",
        "\n",
        "        results = []\n",
        "        img_names = []\n",
        "\n",
        "        # dealing with Friends\n",
        "        if status == 0:\n",
        "            # get profile links of friends\n",
        "            results = [x.get_attribute('href') for x in elements]\n",
        "            results = [create_original_link(x) for x in results]\n",
        "\n",
        "            # get names of friends\n",
        "            people_names = [x.find_element_by_tag_name(\"img\").get_attribute(\"aria-label\") for x in elements]\n",
        "\n",
        "            # download friends' photos\n",
        "            try:\n",
        "                if download_friends_photos:\n",
        "                    if friends_small_size:\n",
        "                        img_links = [x.find_element_by_css_selector('img').get_attribute('src') for x in elements]\n",
        "                    else:\n",
        "                        links = []\n",
        "                        for friend in results:\n",
        "                            try:\n",
        "                                driver.get(friend)\n",
        "                                WebDriverWait(driver, 30).until(\n",
        "                                    EC.presence_of_element_located((By.CLASS_NAME, \"profilePicThumb\")))\n",
        "                                l = driver.find_element_by_class_name(\"profilePicThumb\").get_attribute('href')\n",
        "                            except:\n",
        "                                l = \"None\"\n",
        "\n",
        "                            links.append(l)\n",
        "\n",
        "                        for i in range(len(links)):\n",
        "                            if links[i] is None:\n",
        "                                links[i] = \"None\"\n",
        "                            elif links[i].find('picture/view') != -1:\n",
        "                                links[i] = \"None\"\n",
        "\n",
        "                        img_links = get_facebook_images_url(links)\n",
        "\n",
        "                    folder_names = [\"Friend's Photos\", \"Mutual Friends' Photos\", \"Following's Photos\",\n",
        "                                    \"Follower's Photos\", \"Work Friends Photos\",\n",
        "                                    \"College Friends Photos\", \"Current City Friends Photos\", \"Hometown Friends Photos\"]\n",
        "                    print(\"Downloading \" + folder_names[current_section])\n",
        "\n",
        "                    img_names = image_downloader(img_links, folder_names[current_section])\n",
        "                else:\n",
        "                    img_names = [\"None\"] * len(results)\n",
        "            except:\n",
        "                print(\"Exception (Images)\", str(status), \"Status =\", current_section, sys.exc_info()[0])\n",
        "\n",
        "        # dealing with Photos\n",
        "        elif status == 1:\n",
        "            results = [x.get_attribute('href') for x in elements]\n",
        "            results.pop(0)\n",
        "\n",
        "            try:\n",
        "                if download_uploaded_photos:\n",
        "                    if photos_small_size:\n",
        "                        background_img_links = driver.find_elements_by_xpath(\"//*[contains(@id, 'pic_')]/div/i\")\n",
        "                        background_img_links = [x.get_attribute('style') for x in background_img_links]\n",
        "                        background_img_links = [((x.split('(')[1]).split(')')[0]).strip('\"') for x in\n",
        "                                                background_img_links]\n",
        "                    else:\n",
        "                        background_img_links = get_facebook_images_url(results)\n",
        "\n",
        "                    folder_names = [\"Uploaded Photos\", \"Tagged Photos\"]\n",
        "                    print(\"Downloading \" + folder_names[current_section])\n",
        "\n",
        "                    img_names = image_downloader(background_img_links, folder_names[current_section])\n",
        "                else:\n",
        "                    img_names = [\"None\"] * len(results)\n",
        "            except:\n",
        "                print(\"Exception (Images)\", str(status), \"Status =\", current_section, sys.exc_info()[0])\n",
        "\n",
        "        # dealing with Videos\n",
        "        elif status == 2:\n",
        "            results = elements[0].find_elements_by_css_selector('li')\n",
        "            results = [x.find_element_by_css_selector('a').get_attribute('href') for x in results]\n",
        "\n",
        "            try:\n",
        "                if results[0][0] == '/':\n",
        "                    results = [r.pop(0) for r in results]\n",
        "                    results = [(\"https://en-gb.facebook.com/\" + x) for x in results]\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # dealing with About Section\n",
        "        elif status == 3:\n",
        "            results = elements[0].text\n",
        "            f.writelines(results)\n",
        "\n",
        "        # dealing with Posts\n",
        "        elif status == 4:\n",
        "            extract_and_write_posts(elements, name)\n",
        "            return\n",
        "\n",
        "        \"\"\"Write results to file\"\"\"\n",
        "        if status == 0:\n",
        "            for i in range(len(results)):\n",
        "                # friend's profile link\n",
        "                f.writelines(results[i])\n",
        "                f.write(',')\n",
        "\n",
        "                # friend's name\n",
        "                f.writelines(people_names[i])\n",
        "                f.write(',')\n",
        "\n",
        "                # friend's downloaded picture id\n",
        "                f.writelines(img_names[i])\n",
        "                f.write('\\n')\n",
        "\n",
        "        elif status == 1:\n",
        "            for i in range(len(results)):\n",
        "                # image's link\n",
        "                f.writelines(results[i])\n",
        "                f.write(',')\n",
        "\n",
        "                # downloaded picture id\n",
        "                f.writelines(img_names[i])\n",
        "                f.write('\\n')\n",
        "\n",
        "        elif status == 2:\n",
        "            for x in results:\n",
        "                f.writelines(x + \"\\n\")\n",
        "\n",
        "        f.close()\n",
        "\n",
        "    except:\n",
        "        print(\"Exception (save_to_file)\", \"Status =\", str(status), sys.exc_info()[0])\n",
        "\n",
        "    return\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rAc2Bq8SzQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scrape_data(id, scan_list, section, elements_path, save_status, file_names):\n",
        "    \"\"\"Given some parameters, this function can scrap friends/photos/videos/about/posts(statuses) of a profile\"\"\"\n",
        "    page = []\n",
        "\n",
        "    if save_status == 4:\n",
        "        page.append(id)\n",
        "\n",
        "    for i in range(len(section)):\n",
        "        page.append(id + section[i])\n",
        "\n",
        "    for i in range(len(scan_list)):\n",
        "        try:\n",
        "            driver.get(page[i])\n",
        "\n",
        "            if (save_status == 0) or (save_status == 1) or (\n",
        "                    save_status == 2):  # Only run this for friends, photos and videos\n",
        "\n",
        "                # the bar which contains all the sections\n",
        "                sections_bar = driver.find_element_by_xpath(\"//*[@class='_3cz'][1]/div[2]/div[1]\")\n",
        "\n",
        "                if sections_bar.text.find(scan_list[i]) == -1:\n",
        "                    continue\n",
        "\n",
        "            if save_status != 3:\n",
        "                scroll()\n",
        "\n",
        "            data = driver.find_elements_by_xpath(elements_path[i])\n",
        "\n",
        "            save_to_file(file_names[i], data, save_status, i)\n",
        "\n",
        "        except:\n",
        "            print(\"Exception (scrape_data)\", str(i), \"Status =\", str(save_status), sys.exc_info()[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y07-h6q3S5lj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_original_link(url):\n",
        "    if url.find(\".php\") != -1:\n",
        "        original_link = \"https://en-gb.facebook.com/\" + ((url.split(\"=\"))[1])\n",
        "\n",
        "        if original_link.find(\"&\") != -1:\n",
        "            original_link = original_link.split(\"&\")[0]\n",
        "\n",
        "    elif url.find(\"fnr_t\") != -1:\n",
        "        original_link = \"https://en-gb.facebook.com/\" + ((url.split(\"/\"))[-1].split(\"?\")[0])\n",
        "    elif url.find(\"_tab\") != -1:\n",
        "        original_link = \"https://en-gb.facebook.com/\" + (url.split(\"?\")[0]).split(\"/\")[-1]\n",
        "    else:\n",
        "        original_link = url\n",
        "\n",
        "    return original_link\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS7TP6YnS9Qz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_folder(folder):\n",
        "    if not os.path.exists(folder):\n",
        "        os.mkdir(folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jByF-IC0S__y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scrap_profile(ids):\n",
        "    folder = os.path.join(os.getcwd(), \"Data\")\n",
        "    create_folder(folder)\n",
        "    os.chdir(folder)\n",
        "\n",
        "    # execute for all profiles given in input.txt file\n",
        "    for id in ids:\n",
        "\n",
        "        driver.get(id)\n",
        "        url = driver.current_url\n",
        "        id = create_original_link(url)\n",
        "\n",
        "        print(\"\\nScraping:\", id)\n",
        "\n",
        "        try:\n",
        "            target_dir = os.path.join(folder, id.split('/')[-1])\n",
        "            create_folder(target_dir)\n",
        "            os.chdir(target_dir)\n",
        "        except:\n",
        "            print(\"Some error occurred in creating the profile directory.\")\n",
        "            continue\n",
        "\n",
        "        # ----------------------------------------------------------------------------\n",
        "        print(\"----------------------------------------\")\n",
        "        print(\"Friends..\")\n",
        "        # setting parameters for scrape_data() to scrape friends\n",
        "        scan_list = [\"All\", \"Mutual Friends\", \"Following\", \"Followers\", \"Work\", \"College\", \"Current City\", \"Hometown\"]\n",
        "        section = [\"/friends\", \"/friends_mutual\", \"/following\", \"/followers\", \"/friends_work\", \"/friends_college\",\n",
        "                   \"/friends_current_city\",\n",
        "                   \"/friends_hometown\"]\n",
        "        elements_path = [\"//*[contains(@id,'pagelet_timeline_medley_friends')][1]/div[2]/div/ul/li/div/a\",\n",
        "                         \"//*[contains(@id,'pagelet_timeline_medley_friends')][1]/div[2]/div/ul/li/div/a\",\n",
        "                         \"//*[contains(@class,'_3i9')][1]/div/div/ul/li[1]/div[2]/div/div/div/div/div[2]/ul/li/div/a\",\n",
        "                         \"//*[contains(@class,'fbProfileBrowserListItem')]/div/a\",\n",
        "                         \"//*[contains(@id,'pagelet_timeline_medley_friends')][1]/div[2]/div/ul/li/div/a\",\n",
        "                         \"//*[contains(@id,'pagelet_timeline_medley_friends')][1]/div[2]/div/ul/li/div/a\",\n",
        "                         \"//*[contains(@id,'pagelet_timeline_medley_friends')][1]/div[2]/div/ul/li/div/a\",\n",
        "                         \"//*[contains(@id,'pagelet_timeline_medley_friends')][1]/div[2]/div/ul/li/div/a\"]\n",
        "        file_names = [\"All Friends.txt\", \"Mutual Friends.txt\", \"Following.txt\", \"Followers.txt\", \"Work Friends.txt\",\n",
        "                      \"College Friends.txt\",\n",
        "                      \"Current City Friends.txt\", \"Hometown Friends.txt\"]\n",
        "        save_status = 0\n",
        "\n",
        "        scrape_data(id, scan_list, section, elements_path, save_status, file_names)\n",
        "        print(\"Friends Done!\")\n",
        "\n",
        "        # ----------------------------------------------------------------------------\n",
        "\n",
        "        print(\"----------------------------------------\")\n",
        "        print(\"Photos..\")\n",
        "        print(\"Scraping Links..\")\n",
        "        # setting parameters for scrape_data() to scrap photos\n",
        "        scan_list = [\"'s Photos\", \"Photos of\"]\n",
        "        section = [\"/photos_all\", \"/photos_of\"]\n",
        "        elements_path = [\"//*[contains(@id, 'pic_')]\"] * 2\n",
        "        file_names = [\"Uploaded Photos.txt\", \"Tagged Photos.txt\"]\n",
        "        save_status = 1\n",
        "\n",
        "        scrape_data(id, scan_list, section, elements_path, save_status, file_names)\n",
        "        print(\"Photos Done!\")\n",
        "\n",
        "        # ----------------------------------------------------------------------------\n",
        "        print(\"----------------------------------------\")\n",
        "        print(\"Videos:\")\n",
        "        # setting parameters for scrape_data() to scrap videos\n",
        "        scan_list = [\"'s Videos\", \"Videos of\"]\n",
        "        section = [\"/videos_by\", \"/videos_of\"]\n",
        "        elements_path = [\"//*[contains(@id, 'pagelet_timeline_app_collection_')]/ul\"] * 2\n",
        "        file_names = [\"Uploaded Videos.txt\", \"Tagged Videos.txt\"]\n",
        "        save_status = 2\n",
        "\n",
        "        scrape_data(id, scan_list, section, elements_path, save_status, file_names)\n",
        "        print(\"Videos Done!\")\n",
        "        # ----------------------------------------------------------------------------\n",
        "\n",
        "        print(\"----------------------------------------\")\n",
        "        print(\"About:\")\n",
        "        # setting parameters for scrape_data() to scrap the about section\n",
        "        scan_list = [None] * 7\n",
        "        section = [\"/about?section=overview\", \"/about?section=education\", \"/about?section=living\",\n",
        "                   \"/about?section=contact-info\", \"/about?section=relationship\", \"/about?section=bio\",\n",
        "                   \"/about?section=year-overviews\"]\n",
        "        elements_path = [\"//*[contains(@id, 'pagelet_timeline_app_collection_')]/ul/li/div/div[2]/div/div\"] * 7\n",
        "        file_names = [\"Overview.txt\", \"Work and Education.txt\", \"Places Lived.txt\", \"Contact and Basic Info.txt\",\n",
        "                      \"Family and Relationships.txt\", \"Details About.txt\", \"Life Events.txt\"]\n",
        "        save_status = 3\n",
        "\n",
        "        scrape_data(id, scan_list, section, elements_path, save_status, file_names)\n",
        "        print(\"About Section Done!\")\n",
        "\n",
        "        # ----------------------------------------------------------------------------\n",
        "        print(\"----------------------------------------\")\n",
        "        print(\"Posts:\")\n",
        "        # setting parameters for scrape_data() to scrap posts\n",
        "        scan_list = [None]\n",
        "        section = []\n",
        "        elements_path = ['//div[@class=\"_5pcb _4b0l _2q8l\"]']\n",
        "\n",
        "        file_names = [\"Posts.txt\"]\n",
        "        save_status = 4\n",
        "\n",
        "        scrape_data(id, scan_list, section, elements_path, save_status, file_names)\n",
        "        print(\"Posts(Statuses) Done!\")\n",
        "        print(\"----------------------------------------\")\n",
        "    # ----------------------------------------------------------------------------\n",
        "\n",
        "    print(\"\\nProcess Completed.\")\n",
        "\n",
        "    return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65hL9TtKTIcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def safe_find_element_by_id(driver, elem_id):\n",
        "    try:\n",
        "        return driver.find_element_by_id(elem_id)\n",
        "    except NoSuchElementException:\n",
        "        return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xbus3I0TNWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def login(email, password):\n",
        "    \"\"\" Logging into our own profile \"\"\"\n",
        "\n",
        "    try:\n",
        "        global driver\n",
        "\n",
        "        options = Options()\n",
        "\n",
        "        #  Code to disable notifications pop up of Chrome Browser\n",
        "        options.add_argument(\"--disable-notifications\")\n",
        "        options.add_argument(\"--disable-infobars\")\n",
        "        options.add_argument(\"--mute-audio\")\n",
        "        # options.add_argument(\"headless\")\n",
        "\n",
        "        try:\n",
        "#             platform_ = platform.system().lower()\n",
        "#             if platform_ in ['linux', 'darwin']:\n",
        "#                 driver = webdriver.Chrome(executable_path=\"./chromedriver\", options=options)\n",
        "#             else:\n",
        "              driver = webdriver.Chrome(executable_path=\"./chromedriver.exe\", options=options)\n",
        "        except:\n",
        "            print(\"Kindly replace the Chrome Web Driver with the latest one from \"\n",
        "                  \"http://chromedriver.chromium.org/downloads \"\n",
        "                  \"and also make sure you have the latest Chrome Browser version.\"\n",
        "                  \"\\nYour OS: {}\".format(platform_)\n",
        "                  )\n",
        "            exit()\n",
        "\n",
        "        driver.get(\"https://en-gb.facebook.com\")\n",
        "        driver.maximize_window()\n",
        "\n",
        "        # filling the form\n",
        "        driver.find_element_by_name('email').send_keys(email)\n",
        "        driver.find_element_by_name('pass').send_keys(password)\n",
        "\n",
        "        # clicking on login button\n",
        "        driver.find_element_by_id('loginbutton').click()\n",
        "\n",
        "        # if your account uses multi factor authentication\n",
        "        mfa_code_input = safe_find_element_by_id(driver, 'approvals_code')\n",
        "\n",
        "        if mfa_code_input is None:\n",
        "            return\n",
        "\n",
        "        mfa_code_input.send_keys(input(\"Enter MFA code: \"))\n",
        "        driver.find_element_by_id('checkpointSubmitButton').click()\n",
        "\n",
        "        # there are so many screens asking you to verify things. Just skip them all\n",
        "        while safe_find_element_by_id(driver, 'checkpointSubmitButton') is not None:\n",
        "            dont_save_browser_radio = safe_find_element_by_id(driver, 'u_0_3')\n",
        "            if dont_save_browser_radio is not None:\n",
        "                dont_save_browser_radio.click()\n",
        "\n",
        "            driver.find_element_by_id('checkpointSubmitButton').click()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"There's some error in log in.\")\n",
        "        print(sys.exc_info()[0])\n",
        "        exit()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1kMgwQZTbD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    with open('credentials.txt') as f:\n",
        "        email = f.readline().split('\"')[1]\n",
        "        password = f.readline().split('\"')[1]\n",
        "\n",
        "        if email == \"\" or password == \"\":\n",
        "            print(\"Your email or password is missing. Kindly write them in credentials.txt\")\n",
        "            exit()\n",
        "\n",
        "    ids = [\"https://en-gb.facebook.com/\" + line.split(\"/\")[-1] for line in open(\"input.txt\", newline='\\n')]\n",
        "\n",
        "    if len(ids) > 0:\n",
        "        print(\"\\nStarting Scraping...\")\n",
        "\n",
        "        login(email, password)\n",
        "        scrap_profile(ids)\n",
        "        driver.close()\n",
        "    else:\n",
        "        print(\"Input file is empty.\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xtpxq2AqTeFR",
        "colab_type": "code",
        "outputId": "13864311-0a37-468a-83f4-eabe0af47b18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    # get things rolling\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting Scraping...\n",
            "There's some error in log in.\n",
            "<class 'NameError'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-ddde85f42746>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# get things rolling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-10f1106eb5f5>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memail\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mscrap_profile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-2e249d9e4975>\u001b[0m in \u001b[0;36mscrap_profile\u001b[0;34m(ids)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_original_link\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_udqtM4cUSaT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('credentials.txt') as f:\n",
        "        email = f.readline().split('\"')[1]\n",
        "        password = f.readline().split('\"')[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlM5GZNAaQ4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids = [\"https://en-gb.facebook.com/\" + line.split(\"/\")[-1] for line in open(\"input.txt\", newline='\\n')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haGpErbFalph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzAL1kQJamaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}